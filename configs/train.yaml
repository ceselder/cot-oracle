# CoT Oracle Training Config
# Set n: 0 to disable a task

tasks:
  full_recon:
    n: 40000
    description: "Reconstruct full CoT from stride activations"

  next_step:
    n: 30000
    description: "Predict next ~50 tokens of CoT"

  answer_pred:
    n: 20000
    description: "Predict final answer from partial CoT"

  partial_answer:
    n: 20000
    description: "What would the model answer if stopped at X%? (vLLM targets)"

  correctness:
    n: 15000
    description: "Did the model get the right answer?"

  decorative:
    n: 25000
    description: "Is the CoT decorative or load-bearing?"

  domain:
    n: 0
    description: "What domain is this problem?"

  reasoning_term:
    n: 15000
    description: "Will the model emit </think> soon?"

  conv_qa:
    n: 10000
    description: "Answer conversational questions about the CoT"

  answer_trajectory:
    n: 20000
    description: "What does the model currently think the answer is? (per-sentence, precompute-only)"

  atypical_answer:
    n: 0
    description: "Is this a majority or minority answer? (from 25-rollout distributions)"

  prompt_inversion:
    n: 0
    description: "Reconstruct the original question/prompt from CoT activations"

  compqa:
    n: 8000
    description: "Answer questions about CoT reasoning quality (10 types, Gemini GT)"

  hint_admission:
    n: 0
    description: "Did the model use an external hint? What was it?"

# Training
training:
  lr: 0.00001
  batch_size: 16             # per-GPU micro-batch size (constrained by VRAM)
  effective_batch_size: 128  # total across GPUs + accumulation (invariant to GPU count)
  eval_batch_size: 4
  epochs: 1
  warmup_fraction: 0.1
  max_grad_norm: 1.0
  steering_coefficient: 1.0
  gradient_checkpointing: true
  task_order: shuffled    # "shuffled" (default) or "sequential" (train tasks one at a time)
  seed: 42

# Activation extraction
activations:
  stride: 5
  n_prompt_positions: 5
  position_encoding: false   # sinusoidal PE for activation vectors
  pe_alpha: 0.1              # PE mixing coefficient (only used if position_encoding: true)

# Eval
eval:
  eval_dir: data/evals
  eval_steps: 2000
  save_steps: 10000
  rot13_start_step: 2000
  # All unfaithfulness evals to run during training (pulled from HF)
  # Entries can be plain strings or dicts with baselines for wandb reference lines
  unfaith_evals:
    - hinted_mcq:
        baselines:
          linear_probe: 0.65
          attention_probe: 0.70
          llm_monitor: 0.50
    - hinted_mcq_truthfulqa
    - sycophancy_v2_riya:
        baselines:
          llm_monitor: 0.42
    - decorative_cot:
        baselines:
          linear_probe: 0.72
          llm_monitor: 0.55
    - sentence_insertion
    - reasoning_termination_riya
    - atypical_answer_riya
    - atypical_answer_mcq
    - cybercrime_ood
    - forced_answer_entropy_riya
    - rot13_reconstruction
    - compqa

# Data â€” HF dataset IDs auto-download; local paths used as-is
data:
  corpus: mats-10-sprint-cs-jb/cot-oracle-corpus-v5
  precomputed_dir: data/precomputed
  activation_cache_dir: data/eval_precomputed  # auto-populates on first eval run
  atypical_data_path: mats-10-sprint-cs-jb/qwen3-8b-atypical-answer-rollouts
  hint_admission_data_path: mats-10-sprint-cs-jb/qwen3-8b-hint-admission-rollouts

# Model
model:
  name: Qwen/Qwen3-8B
  ao_checkpoint: adamkarvonen/checkpoints_latentqa_cls_past_lens_addition_Qwen3-8B
  fresh_lora: false

# Baselines
baselines:
  output_dir: data/baseline_results
  log_dir: logs/baselines

  evals:
    - hinted_mcq
    - sycophancy_v2_riya
    - decorative_cot
    - reasoning_termination_riya
    - rot13_reconstruction
    - thought_anchors
    - thought_branches

  stride: 5

  linear_probe:
    layers: [9, 18, 27]       # also runs concat of all 3
    k_folds: 5
    lr: 0.01
    epochs: 100
    weight_decay: 0.0001

  attention_probe:
    n_layers: 36               # all layers
    k_folds: 5
    n_heads: 4
    hidden_dim: 256
    lr: 0.001
    epochs: 50
    patience: 10

  original_ao:
    checkpoint: adamkarvonen/checkpoints_latentqa_cls_past_lens_addition_Qwen3-8B

  llm_monitor:
    model: google/gemini-3-flash
    api_base: https://openrouter.ai/api/v1
    max_tokens: 300
    temperature: 0.0

  patchscopes:
    source_layers: [9, 18, 27]
    injection_layer: 1
    steering_coefficient: 1.0
    max_new_tokens: 100

# Output
output:
  save_dir: checkpoints
  wandb_project: cot_oracle
  wandb_entity: MATS10-CS-JB
  wandb_run: null  # auto-generated if null
