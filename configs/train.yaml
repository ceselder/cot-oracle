# CoT Oracle Training Config
# Set n: 0 to disable a task

tasks:
  full_recon:
    n: 40000
    description: "Reconstruct full CoT from stride activations"

  next_step:
    n: 30000
    description: "Predict next ~50 tokens of CoT"

  answer_pred:
    n: 20000
    description: "Predict final answer from partial CoT"

  partial_answer:
    n: 20000
    description: "What would the model answer if stopped at X%? (vLLM targets)"

  load_bearing:
    n: 15000
    description: "Is this CoT load-bearing or decorative?"

  correctness:
    n: 15000
    description: "Did the model get the right answer?"

  decorative:
    n: 15000
    description: "Is the CoT decorative?"

  domain:
    n: 0
    description: "What domain is this problem?"

  reasoning_term:
    n: 15000
    description: "Will the model emit </think> soon?"

  conv_qa:
    n: 10000
    description: "Answer conversational questions about the CoT"

  answer_trajectory:
    n: 0
    description: "What does the model currently think the answer is? (per-sentence, precompute-only)"

# Training
training:
  lr: 0.00001
  batch_size: 8
  eval_batch_size: 2
  epochs: 1
  warmup_fraction: 0.1
  max_grad_norm: 1.0
  steering_coefficient: 1.0
  gradient_checkpointing: true
  task_order: sequential    # "sequential" (default, curriculum) or "shuffled" (interleaved)
  seed: 42

# Activation extraction
activations:
  stride: 5
  max_positions_per_layer: 20
  n_prompt_positions: 5
  position_encoding: false   # sinusoidal PE for activation vectors
  pe_alpha: 0.1              # PE mixing coefficient (only used if position_encoding: true)

# Eval
eval:
  eval_steps: 500
  save_steps: 2000
  unfaith_eval_steps: 500
  unfaith_eval_items: 20
  eval_dir: data/evals
  rot13_start_step: 2000

# Data
data:
  corpus: data/cot_corpus_v5/corpus_medium.jsonl
  precomputed_dir: data/precomputed
  concept_corpus: data/concept_corpus/corpus_full.jsonl
  cotqa_path: data/concept_corpus/corpus_full_conv_qa_llm.jsonl
  activation_cache_dir: data/eval_precomputed  # auto-populates on first eval run

# Model
model:
  name: Qwen/Qwen3-8B
  ao_checkpoint: adamkarvonen/checkpoints_latentqa_cls_past_lens_addition_Qwen3-8B
  fresh_lora: false

# Output
output:
  save_dir: checkpoints/v6
  wandb_project: cot_oracle
  wandb_entity: MATS10-CS-JB
  wandb_run: null  # auto-generated if null
