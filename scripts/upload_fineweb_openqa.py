#!/usr/bin/env python3
"""
Upload FineWeb open-ended QA dataset to HuggingFace with train/test split.

Usage:
    python scripts/upload_fineweb_openqa.py --dry-run
    python scripts/upload_fineweb_openqa.py
"""

import argparse
import json
import os
import random
from pathlib import Path

import pandas as pd
from dotenv import load_dotenv
from huggingface_hub import HfApi, create_repo

load_dotenv(os.path.expanduser("~/.env"))

PROJECT_ROOT = Path(__file__).parent.parent
REPO_ID = "mats-10-sprint-cs-jb/fineweb-convqa"


def main():
    parser = argparse.ArgumentParser(description="Upload FineWeb open-ended QA to HF")
    parser.add_argument("--input", default="data/fineweb_openqa/fineweb_openqa.jsonl")
    parser.add_argument("--test-fraction", type=float, default=0.1)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--dry-run", action="store_true")
    args = parser.parse_args()

    # Load JSONL
    rows = []
    with open(args.input) as f:
        for line in f:
            if line.strip():
                rows.append(json.loads(line))
    print(f"Loaded {len(rows)} rows from {args.input}")

    df = pd.DataFrame(rows)

    # Stats
    print(f"\n  Excerpt token lengths:")
    print(f"    mean: {df['excerpt_n_tokens'].mean():.0f}, median: {df['excerpt_n_tokens'].median():.0f}, min: {df['excerpt_n_tokens'].min()}, max: {df['excerpt_n_tokens'].max()}")

    # Question generation prompts used
    prompts_used = df["question_generation_prompt"].unique().tolist()
    print(f"\n  Question generation prompts: {len(prompts_used)}")
    for i, p in enumerate(prompts_used):
        print(f"    {i+1}. {p[:80]}...")

    # Train/test split (random row-level, since each row is independent)
    rng = random.Random(args.seed)
    indices = list(range(len(df)))
    rng.shuffle(indices)
    test_end = int(len(indices) * args.test_fraction)
    test_idx = set(indices[:test_end])

    df_train = df.iloc[[i for i in range(len(df)) if i not in test_idx]]
    df_test = df.iloc[list(test_idx)]
    print(f"\n  Split: {len(df_train)} train, {len(df_test)} test")

    # Save parquets
    output_dir = PROJECT_ROOT / "data" / "hf_uploads" / "fineweb_convqa"
    output_dir.mkdir(parents=True, exist_ok=True)

    train_path = output_dir / "train.parquet"
    test_path = output_dir / "test.parquet"
    df_train.to_parquet(train_path, index=False)
    df_test.to_parquet(test_path, index=False)
    print(f"  Saved {len(df_train)} train → {train_path}")
    print(f"  Saved {len(df_test)} test → {test_path}")

    # Build README
    prompts_section = ""
    for i, p in enumerate(prompts_used):
        label = "**(Used)**" if i == 0 else ""
        prompts_section += f"\n{i+1}. {label}\n   > {p}\n"

    readme = f"""---
tags:
  - cot-oracle
  - fineweb
  - question-answering
license: mit
---

# FineWeb Open-Ended ConvQA

Open-ended question-answer dataset grounded in FineWeb web document excerpts.

Each excerpt is sent to Gemini 2.5 Flash Lite, which generates an open-ended question
about the content (`prompt`), then answers it (`target_response`).

- **Round 1:** Gemini sees the excerpt, generates a question requiring understanding and reasoning.
- **Round 2:** Gemini sees the excerpt + the question, produces an answer.

## Splits

| Split | Rows |
|-------|------|
| train | {len(df_train)} |
| test | {len(df_test)} |

## Excerpt Token Length Distribution

| Stat | Value |
|------|-------|
| Mean | {df['excerpt_n_tokens'].mean():.0f} |
| Median | {df['excerpt_n_tokens'].median():.0f} |
| Min | {df['excerpt_n_tokens'].min()} |
| Max | {df['excerpt_n_tokens'].max()} |

Token counts use the Qwen3-8B tokenizer.

## Question Generation Prompts
{prompts_section}
## Schema

| Field | Description |
|-------|-------------|
| `excerpt` | FineWeb excerpt text |
| `excerpt_n_tokens` | Token length of excerpt (Qwen3-8B tokenizer) |
| `prompt` | Open-ended question generated by Gemini (Round 1) |
| `target_response` | Gemini's answer to the question (Round 2) |
| `question_generation_prompt` | System prompt used for question generation |
| `fineweb_id` | ID from FineWeb source |
| `fineweb_url` | URL from FineWeb source |

## Usage

```python
from datasets import load_dataset
ds = load_dataset("{REPO_ID}")
train = ds["train"]
test = ds["test"]
```
"""

    with open(output_dir / "README.md", "w") as f:
        f.write(readme)

    if not args.dry_run:
        token = os.environ["HF_TOKEN"]
        api = HfApi(token=token)
        create_repo(REPO_ID, repo_type="dataset", exist_ok=True, token=token)
        api.upload_folder(folder_path=str(output_dir), repo_id=REPO_ID, repo_type="dataset")
        print(f"  Uploaded to https://huggingface.co/datasets/{REPO_ID}")
    else:
        print(f"  Dry run — would upload to https://huggingface.co/datasets/{REPO_ID}")

    print("\nDone!")


if __name__ == "__main__":
    main()
