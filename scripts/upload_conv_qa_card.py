#!/usr/bin/env python3
"""Upload model card for the conv QA dataset."""
import os

from huggingface_hub import HfApi

HF_TOKEN = os.environ["HF_TOKEN"]

CARD = """---
tags:
  - cot-oracle
  - chain-of-thought
  - conversational-qa
  - training-data
license: mit
---

# CoT Oracle Training Data: Conversational QA

## Description

10,499 conversational question-answer pairs about chain-of-thought reasoning traces. Each QA pair references a specific entry in the concept corpus (safety/bias datasets) and asks a diverse open-ended question about the reasoning.

Generated by DeepSeek v3.2 via OpenRouter, with 10 question categories covering different aspects of CoT analysis.

## Source datasets

Questions are grounded in CoT traces from:
- **BeaverTails** (safety)
- **BBQ** (bias)
- **TruthfulQA** (factuality)
- **Scruples** (moral reasoning)
- **GSM8K** / **MATH** (mathematical reasoning)
- And other datasets in the ceselder/qwen3-8b-math-cot-corpus collection

## Schema

| Field | Type | Description |
|-------|------|-------------|
| `corpus_id` | str | ID of the source corpus entry (e.g., `concept_beaverta_00729`) |
| `task_family` | str | Always `cot_qa_conversational` |
| `task_type` | str | Question category (see below) |
| `prompt` | str | The activation oracle prompt template |
| `target_response` | str | DeepSeek v3.2 generated answer |
| `answer_length` | str | `short`, `medium`, or `long` |

## Question categories (task_type)

| Category | Count | Example question |
|----------|-------|------------------|
| `conv_content` | 1,077 | Is this about ethics, morality, or social issues? |
| `conv_topic` | 1,074 | What specific topic is being reasoned about? |
| `conv_general` | 1,071 | Summarize what the model is thinking about |
| `conv_behavior` | 1,063 | Is the model being cautious or evasive? |
| `conv_style` | 1,047 | Is the reasoning formal, casual, or technical? |
| `conv_reasoning` | 1,047 | What reasoning strategy is being used? |
| `conv_thematic` | 1,046 | What themes or values underlie this reasoning? |
| `conv_sycophancy` | 1,046 | Is the model agreeing just to be agreeable? |
| `conv_safety` | 1,030 | Is the model applying safety/refusal heuristics? |
| `conv_user_intent` | 998 | What is the user trying to accomplish? |

## Oracle prompt template

The prompt field contains the full oracle query:

    Activations from {N} positions across layers {layers}. {question}

Where `{N}` is the number of activation positions (stride=5, 3 layers), `{layers}` are the injection layers (e.g., 9, 18, 27 for Qwen3-8B), and `{question}` is the specific question about the CoT.

## Source model prompt format

Activations are extracted from Qwen3-8B with thinking enabled. The chat template wraps the question with system/user/assistant tags and a think block containing the CoT response.

## Usage

    from datasets import load_dataset
    ds = load_dataset("ceselder/cot-oracle-conv-qa")
    print(ds["train"][0])

## Generation details

- **Model:** DeepSeek v3.2 via OpenRouter
- **Cost:** ~$1.45 for 10,499 pairs
- **Failures:** 0 (100% success rate)
- **Seed:** 42
"""

api = HfApi(token=HF_TOKEN)
api.upload_file(
    path_or_fileobj=CARD.encode(),
    path_in_repo="README.md",
    repo_id="ceselder/cot-oracle-conv-qa",
    repo_type="dataset",
    token=HF_TOKEN,
    commit_message="Add detailed model card",
)
print("Model card uploaded!")
